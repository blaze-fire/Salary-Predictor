{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>requirements</th>\n",
       "      <th>rating</th>\n",
       "      <th>experience</th>\n",
       "      <th>posting_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Gather Network</td>\n",
       "      <td>Urban Estate Gurgaon, Haryana</td>\n",
       "      <td>20,000 a month</td>\n",
       "      <td>We are actively looking for a few freshers who...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>Agile Placement</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>5,00,000 - 14,00,000 a year</td>\n",
       "      <td>_Strong knowledge of programming and scripting...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>Total work: 6 years</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Client of PlaceElements HR</td>\n",
       "      <td>Thiruvananthapuram, Kerala</td>\n",
       "      <td>5,00,000 - 10,00,000 a year</td>\n",
       "      <td>Experience in working closely with data analys...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>Python: Algorithms: Statistics: 1 yearData Sci...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer - Machine Learning Engineer</td>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>na</td>\n",
       "      <td>Experience with machine learning architectures...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning (Fullstack) at Sadhashiva Nag...</td>\n",
       "      <td>Teqlinx Software Solutions LLC</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>30,00,000 a year</td>\n",
       "      <td>• Extremely strong programming background – da...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job_position  \\\n",
       "0                          Junior Software Developer   \n",
       "1                                 Big Data Developer   \n",
       "2                                     Data Scientist   \n",
       "3      Software Engineer - Machine Learning Engineer   \n",
       "4  Machine Learning (Fullstack) at Sadhashiva Nag...   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                   Gather Network   \n",
       "1                                  Agile Placement   \n",
       "2                       Client of PlaceElements HR   \n",
       "3  Siemens Technology and Services Private Limited   \n",
       "4                   Teqlinx Software Solutions LLC   \n",
       "\n",
       "                        Location                       Salary  \\\n",
       "0  Urban Estate Gurgaon, Haryana               20,000 a month   \n",
       "1              Pune, Maharashtra  5,00,000 - 14,00,000 a year   \n",
       "2     Thiruvananthapuram, Kerala  5,00,000 - 10,00,000 a year   \n",
       "3              Pune, Maharashtra                           na   \n",
       "4           Bengaluru, Karnataka             30,00,000 a year   \n",
       "\n",
       "                                        requirements  rating  \\\n",
       "0  We are actively looking for a few freshers who...   -99.0   \n",
       "1  _Strong knowledge of programming and scripting...   -99.0   \n",
       "2  Experience in working closely with data analys...   -99.0   \n",
       "3  Experience with machine learning architectures...     4.0   \n",
       "4  • Extremely strong programming background – da...   -99.0   \n",
       "\n",
       "                                          experience  posting_frequency  \n",
       "0                                                 na                1.0  \n",
       "1                                Total work: 6 years                1.0  \n",
       "2  Python: Algorithms: Statistics: 1 yearData Sci...                1.0  \n",
       "3                                                 na                1.0  \n",
       "4                                                 na                1.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate max and min salary per annum\n",
    "\n",
    "yearly_min = {}\n",
    "yearly_max = {}\n",
    "\n",
    "def salary(df):\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        \n",
    "        if df['Salary'][i] == '-999':\n",
    "            yearly_min[i] = 0\n",
    "            yearly_max[i] = 0\n",
    "            \n",
    "        if 'a year' in df['Salary'][i]:\n",
    "            sal_min = df['Salary'][i].split('-')[0].replace('a year','').replace(',','')\n",
    "            yearly_min[i] = int(sal_min)\n",
    "            \n",
    "            try:\n",
    "                sal_max = df['Salary'][i].split('-')[1].replace('a year','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max)\n",
    "                \n",
    "            # if only single value present will be stored in both max and min, so the average comes accuate\n",
    "            except:\n",
    "                sal_max = df['Salary'][i].split('-')[0].replace('a year','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max)\n",
    "            \n",
    "        if 'a month' in df['Salary'][i]:\n",
    "            sal_min = df['Salary'][i].split('-')[0].replace('a month','').replace(',','')\n",
    "            yearly_min[i] = int(sal_min) * 12\n",
    "            \n",
    "            try:\n",
    "                sal_max = df['Salary'][i].split('-')[1].replace('a month','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 12    \n",
    "                \n",
    "            # if only single value present will be stored in both max and min, so the average comes accuate\n",
    "            except:\n",
    "                sal_max = df['Salary'][i].split('-')[0].replace('a month','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 12\n",
    "                \n",
    "salary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min, max and avg salary columns\n",
    "df['min_sal'] = pd.DataFrame(yearly_min.values(), index= yearly_min.keys())\n",
    "df['max_sal'] = pd.DataFrame(yearly_max.values(), index= yearly_max.keys())\n",
    "df['avg_yearly_sal'] = ( df['min_sal'] + df['max_sal'] )/2\n",
    "df['monthly_sal'] = df['avg_yearly_sal']/12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_yearly_sal'].fillna(0, inplace=True)\n",
    "df['max_sal'].fillna(0, inplace=True)\n",
    "df['min_sal'].fillna(0, inplace=True)\n",
    "df['monthly_sal'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Salary', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience is mentioned in both requirements and experience so we will collect them all and save it in a column of experience "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these requirements mention experienced  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_experience = []\n",
    "for i in df.experience:\n",
    "    temp=[]\n",
    "    for word in i.split():\n",
    "        if word.isdigit():\n",
    "            temp.append(word)\n",
    "    if temp:\n",
    "        temp.sort(reverse=True)\n",
    "        net_experience.append(temp[0])\n",
    "    else:\n",
    "        net_experience.append(-99)\n",
    "df['net_experience'] = net_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net_experience'] = df['net_experience'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_experience = []\n",
    "for i in df.requirements:\n",
    "    temp=[]\n",
    "    for word in i.split():\n",
    "        if word.isdigit():\n",
    "            temp.append(word)\n",
    "    if temp:\n",
    "        temp.sort(reverse=True)\n",
    "        net_experience.append(temp[0])\n",
    "    else:\n",
    "        net_experience.append(-99)\n",
    "df['exp2'] = net_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unwanted values from experience column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['²', '0080091', '2020', '2024', '2019', '90', '88', '32', '48', '40', '50', '24']:\n",
    "    df['exp2'] = df['exp2'].apply(lambda x: str(x).replace(p,'-99'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exp2'] = df['exp2'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where experience required is mentioned in <b>requirements</b> column but missing in <b>experience</b> column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net_experience'] = df['net_experience'].where((df['net_experience']>0), df['exp2'])\n",
    "df.drop('exp2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188    Higher Secondary(12th Pass)\n",
       "294    Higher Secondary(12th Pass)\n",
       "390    Higher Secondary(12th Pass)\n",
       "723    Higher Secondary(12th Pass)\n",
       "Name: experience, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[188, 294, 390, 723]]['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     About the Internship: Selected intern's day-to...\n",
       "111    Full stack developer intern who could work on ...\n",
       "122    We are Hiring for Junior Software Developer In...\n",
       "362    AGNIK is hiring a Data Science Intern with som...\n",
       "749    We are seeking a Web developer Intern responsi...\n",
       "Name: requirements, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[14, 111, 122, 362, 749]]['requirements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Some openings require no experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-151-2cd56dcae9cc>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['net_experience'][[188, 294, 390, 723, 14, 111, 122, 362, 749]] = 0\n",
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['net_experience'][[188, 294, 390, 723, 14, 111, 122, 362, 749]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Educational criteria mentioned by these companies can also be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_level(data):\n",
    "    if 'bachelor' in data.replace('year',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'bachelor'\n",
    "    if 'secondary' in data.replace('year',' ').replace('(',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'secondary'\n",
    "    if 'master' in data.replace('year',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'masters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'] = df['experience'].map(education_level)\n",
    "df['education_level'].fillna('na',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the categories of seniority is only jr, senior or na, we can one hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['education_level'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seniority of these job positions cal also be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seniority(title):\n",
    "    title = str(title) \n",
    "    if 'ii' in title.lower().split() or 'director' in title.lower().split() or 'specialist' in title.lower().split() or 'professional' in title.lower().split() or 'sr.' in title.lower().split() or 'senior' in title.lower().split():\n",
    "        return 'senior'\n",
    "    elif 'i' in title.lower().split() or 'associate' in title.lower().split() or 'junior' in title.lower().split() or 'jr' in title.lower().split()  or 'jr.' in title.lower().split() or 'trainee' in title.lower().split() or 'intern' in title.lower().split() or 'jr.' in title.lower().split():\n",
    "        return 'jr'\n",
    "    else:\n",
    "        return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the seniority of the position applying for\n",
    "df['job_title'] = df['Job_position'].apply(seniority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding rank transforamtion, label encoding, frequency encoding were applied but they had very weak correlation with avg_year_salary <br>\n",
    "as the categories of seniority is only jr, senior or na, we can one hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['job_title'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analyzing the requirements column following are the most popular professions <br>\n",
    "lets store their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jobs(data):\n",
    "    data = data.lower().replace(' ', '')\n",
    "    if 'machinelearning' in data:\n",
    "        return 'machine learning'\n",
    "    \n",
    "    if 'datascientist' in data:\n",
    "        return 'data scientist'\n",
    "    \n",
    "    if 'softwaredeveloper' in data:\n",
    "        return 'software developer'\n",
    "    \n",
    "    if 'softwareengineer' in data:\n",
    "        return 'software engineer'\n",
    "    \n",
    "    if 'deeplearning' in data:\n",
    "        return 'deep learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popular_profession'] = df['requirements'].apply(calc_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popular_profession'] = df['popular_profession'].fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['popular_profession'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the location column and get the state \n",
    "df['State'] = df['Location'].apply(lambda x: x.split(', ')[1] if len(x.split()) > 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Larsen & Toubro Infotech Limited    9\n",
       "Accenture                           8\n",
       "Shaw Academy                        7\n",
       "ANI Calls India Private Limited     6\n",
       "JPMorgan Chase Bank, N.A.           5\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some companies have multiple job openings this could be useful\n",
    "df['Company'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_openings = df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_openings'] = df['Company'].map(job_openings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "df['requirements'].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_descr_len'] = df['requirements'].apply(lambda x: 0 if not x else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>requirements</th>\n",
       "      <th>rating</th>\n",
       "      <th>experience</th>\n",
       "      <th>posting_frequency</th>\n",
       "      <th>min_sal</th>\n",
       "      <th>max_sal</th>\n",
       "      <th>avg_yearly_sal</th>\n",
       "      <th>...</th>\n",
       "      <th>popular_profession</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>na</th>\n",
       "      <th>software developer</th>\n",
       "      <th>software engineer</th>\n",
       "      <th>State</th>\n",
       "      <th>job_openings</th>\n",
       "      <th>job_descr_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Gather Network</td>\n",
       "      <td>Urban Estate Gurgaon, Haryana</td>\n",
       "      <td>We are actively looking for a few freshers who...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>Agile Placement</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>_Strong knowledge of programming and scripting...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>Total work: 6 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Client of PlaceElements HR</td>\n",
       "      <td>Thiruvananthapuram, Kerala</td>\n",
       "      <td>Experience in working closely with data analys...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>Python: Algorithms: Statistics: 1 yearData Sci...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer - Machine Learning Engineer</td>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>Experience with machine learning architectures...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning (Fullstack) at Sadhashiva Nag...</td>\n",
       "      <td>Teqlinx Software Solutions LLC</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>• Extremely strong programming background – da...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job_position  \\\n",
       "0                          Junior Software Developer   \n",
       "1                                 Big Data Developer   \n",
       "2                                     Data Scientist   \n",
       "3      Software Engineer - Machine Learning Engineer   \n",
       "4  Machine Learning (Fullstack) at Sadhashiva Nag...   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                   Gather Network   \n",
       "1                                  Agile Placement   \n",
       "2                       Client of PlaceElements HR   \n",
       "3  Siemens Technology and Services Private Limited   \n",
       "4                   Teqlinx Software Solutions LLC   \n",
       "\n",
       "                        Location  \\\n",
       "0  Urban Estate Gurgaon, Haryana   \n",
       "1              Pune, Maharashtra   \n",
       "2     Thiruvananthapuram, Kerala   \n",
       "3              Pune, Maharashtra   \n",
       "4           Bengaluru, Karnataka   \n",
       "\n",
       "                                        requirements  rating  \\\n",
       "0  We are actively looking for a few freshers who...   -99.0   \n",
       "1  _Strong knowledge of programming and scripting...   -99.0   \n",
       "2  Experience in working closely with data analys...   -99.0   \n",
       "3  Experience with machine learning architectures...     4.0   \n",
       "4  • Extremely strong programming background – da...   -99.0   \n",
       "\n",
       "                                          experience  posting_frequency  \\\n",
       "0                                                 na                1.0   \n",
       "1                                Total work: 6 years                1.0   \n",
       "2  Python: Algorithms: Statistics: 1 yearData Sci...                1.0   \n",
       "3                                                 na                1.0   \n",
       "4                                                 na                1.0   \n",
       "\n",
       "     min_sal    max_sal  avg_yearly_sal  ...  popular_profession  \\\n",
       "0   240000.0   240000.0        240000.0  ...                  na   \n",
       "1   500000.0  1400000.0        950000.0  ...                  na   \n",
       "2   500000.0  1000000.0        750000.0  ...      data scientist   \n",
       "3        0.0        0.0             0.0  ...    machine learning   \n",
       "4  3000000.0  3000000.0       3000000.0  ...                  na   \n",
       "\n",
       "   data scientist deep learning  machine learning  na  software developer  \\\n",
       "0               0             0                 0   1                   0   \n",
       "1               0             0                 0   1                   0   \n",
       "2               1             0                 0   0                   0   \n",
       "3               0             0                 1   0                   0   \n",
       "4               0             0                 0   1                   0   \n",
       "\n",
       "   software engineer        State  job_openings  job_descr_len  \n",
       "0                  0      Haryana             1            156  \n",
       "1                  0  Maharashtra             1            158  \n",
       "2                  0       Kerala             1            156  \n",
       "3                  0  Maharashtra             4            149  \n",
       "4                  0    Karnataka             1            160  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Job skills\n",
    "\n",
    "As due to covid-19 many people working in the industry have lost their jobs, and according to news articles the skill demand for job industry \n",
    "is also changing, lets take a look at the skills, in demand in the job industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = df['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = list(filter(None, requirements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split punctuation \n",
    "for p in ['-','(',')','.','/']:\n",
    "    job_descr = []\n",
    "    for i in range(0, len(requirements)):\n",
    "        c = requirements[i].split(p)\n",
    "        for x in c:\n",
    "            x.replace('.',' ')\n",
    "            job_descr.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert to lower case\n",
    "for x in range(0,len(job_descr)):\n",
    "    for p in ['.', '-', ')', '(', '…', ',', ':', \"'\"]:\n",
    "        job_descr[x] = job_descr[x].replace(p,' ')\n",
    "    job_descr[x] = job_descr[x].lower()       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing keywords from custom keyword list\n",
    "f = open(\"skills.txt\",\"r\",) \n",
    "skills=[]\n",
    "for x in f:\n",
    "    skills.append(x)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in skills:\n",
    "    skills = i.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(skills)):\n",
    "    skills[i] = skills[i].replace(' ','')\n",
    "    skills[i] = skills[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['html', 'css', 'c', 'debugging', 'git', 'graphic', 'database', 'java', 'javascript', 'nodejs', 'apis', 'r', 'ruby', 'php', 'net', 'c#', 'jquery', 'python', 'perl', 'react', 'reactjs', 'ux', 'ui', 'testing', 'analyst', 'springboot', 'jpa', 'microservice', 'postman', 'rest', 'api', 'angular', 'azure', 'aws', 'cloud', 'debugging', 'btech', 'cs', 'idbc', 'porting', 'porting', 'vive', 'go', 'playstation', 'medicine', 'food', 'chromium', 'nodejs', 'js', 'net', 'server', 'architecture', 'mobile', 'b2b', 'healthcare', 'security', 'sql', 'mvc', 'asp', 'version', 'typescript', 'sass', 'pwas', 'ios', 'androis', 'html', 'python.node', 'rdbms', 'mysql', 'script', 'query', 'mongo', 'oops', 'os', 'restful', 'app', 'xamarin', 'financial', 'shell', 'unix', 'script', 'powershell', 'linux', 'game', 'gui', 'unity', 'ai', 'jquery', 'iot', 'freelance', 'bootstrap', 'word', 'excel', 'swift', 'salesforce', 'graphic', 'github', 'flutter', 'c++', 'c#', 'docker', 'stack', 'bug', 'lravel', 'flux', 'redux', 'nlp', 'blockchain', 'vue', 'spark', 'flink', 'beam', 'scala', 'operating', 'system', 'statistics', 'structures', 'algorithms', 'mining', 'cleaning', 'open', 'source', 'information', 'systems', 'visualization']\n"
     ]
    }
   ],
   "source": [
    "print(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing requirements on the basis whether a skill is present in that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df['requirements'] = df['requirements'].apply(lambda x: ' '.join([word for word in x.lower().split() if word in (skills)]))\n",
    "df['requirements'].replace(to_replace='', value='na', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = word_tokenize(str(job_descr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the frequency of a particular skill mentioned in job description\n",
    "def calc_skill_freq(data):\n",
    "    skill_dict = {}\n",
    "\n",
    "    for i in range(1,len(data)):\n",
    "        token = data[i]\n",
    "        if token in skills:\n",
    "            try:\n",
    "                skill_dict[token].add(i)\n",
    "            except:\n",
    "                skill_dict[token] = {i}\n",
    "            \n",
    "    for i in skill_dict:\n",
    "        skill_dict[i] = len(skill_dict[i])\n",
    "        \n",
    "    return skill_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descr_dict = calc_skill_freq(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Companies have mentioned the required skills in job position and some in some description <br>\n",
    "Lets take a look at the skills mentioned in Job description column, then we will add them to get skills in demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation present in job position column\n",
    "def remove_punctuation(df):\n",
    "    for p in ['/', ',', '(', ')', '-', '|', '&', '_', '.', '“', '”', ':']:\n",
    "        df['Job_position'] = df['Job_position'].apply(lambda x: str(x).replace(p,' '))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_punctuation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing stopwords from custom stopwords list\n",
    "f = open(\"stopwords.txt\",\"r\",) \n",
    "stopwords=[]\n",
    "\n",
    "for x in f:\n",
    "    stopwords.append(x)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords:\n",
    "    stopwords = i.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(stopwords)):\n",
    "    stopwords[i] = stopwords[i].replace(\"'\",\"\")\n",
    "    stopwords[i] = stopwords[i].replace(\" \",\"\")\n",
    "    stopwords[i] = stopwords[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'developer', 'software', 'etc', 'engineer']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords from the Job_position column\n",
    "job_role = list(df['Job_position'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stopwords)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job_position'] = df['Job_position'].apply(lambda x: ' '.join([word for word in x.lower().split() if word in (skills)]))\n",
    "df['Job_position'] = df['Job_position'].where(df['Job_position'] != '', 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_role = word_tokenize(str(job_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the frequency of a particular skill mentioned in job role\n",
    "job_role_dict = calc_skill_freq(job_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we first pass all the elements of the first dictionary into the third one and then pass the second dictionary \n",
    "into the third. This will replace the duplicate keys of the first dictionary. <br>\n",
    "More info : (https://www.geeksforgeeks.org/python-merging-two-dictionaries/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_dict = {**job_role_dict, **job_descr_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save this dictionary for now it will be useful for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "skill_file = open('skill_dictionary', 'wb') \n",
    "pickle.dump(skills_dict, skill_file) \n",
    "skill_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create new column for each skill with value equal to the frequency of that skill occurring in that particular cell\n",
    "def calc_freq(df):\n",
    "    for key in list(skills_dict.keys()):\n",
    "        if skills_dict[key] > 15:\n",
    "            skill_calc = []\n",
    "            for i in range(0,len(df)):\n",
    "                count = 0\n",
    "                \n",
    "                # here we are counting frquency from both requirements and Job position column\n",
    "                for word in df['requirements'][i].lower().split() :\n",
    "                    if key in df['Job_position'][i].lower().split():\n",
    "                        count += 1\n",
    "                    if key == word:\n",
    "                        count += 1\n",
    "                        skill_calc.append(count)\n",
    "                    else:\n",
    "                        skill_calc.append(0)\n",
    "                        \n",
    "            df = pd.concat([df, pd.DataFrame(skill_calc, columns=[key])], axis=1)\n",
    "            # all the missing values should be filled with zero as they dont contain that particular skill \n",
    "            df[key] = df[key].fillna(0)\n",
    "    return df\n",
    "df = calc_freq(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As skills from job position and description were added its possible some of them dont appear in description, their frequency wiil be zero so we \n",
    "must drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with constant values\n",
    "df = df.loc[:, (df != df.iloc[0]).any()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1124 entries, 0 to 1123\n",
      "Data columns (total 62 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Job_position        1124 non-null   object \n",
      " 1   Company             1124 non-null   object \n",
      " 2   Location            1124 non-null   object \n",
      " 3   requirements        1124 non-null   object \n",
      " 4   rating              1124 non-null   float64\n",
      " 5   experience          1124 non-null   object \n",
      " 6   posting_frequency   1124 non-null   float64\n",
      " 7   min_sal             1124 non-null   float64\n",
      " 8   max_sal             1124 non-null   float64\n",
      " 9   avg_yearly_sal      1124 non-null   float64\n",
      " 10  monthly_sal         1124 non-null   float64\n",
      " 11  net_experience      1124 non-null   int32  \n",
      " 12  education_level     1124 non-null   object \n",
      " 13  bachelor            1124 non-null   uint8  \n",
      " 14  masters             1124 non-null   uint8  \n",
      " 15  na                  1124 non-null   uint8  \n",
      " 16  secondary           1124 non-null   uint8  \n",
      " 17  job_title           1124 non-null   object \n",
      " 18  jr                  1124 non-null   uint8  \n",
      " 19  na                  1124 non-null   uint8  \n",
      " 20  senior              1124 non-null   uint8  \n",
      " 21  popular_profession  1124 non-null   object \n",
      " 22  data scientist      1124 non-null   uint8  \n",
      " 23  deep learning       1124 non-null   uint8  \n",
      " 24  machine learning    1124 non-null   uint8  \n",
      " 25  na                  1124 non-null   uint8  \n",
      " 26  software developer  1124 non-null   uint8  \n",
      " 27  software engineer   1124 non-null   uint8  \n",
      " 28  State               1124 non-null   object \n",
      " 29  job_openings        1124 non-null   int64  \n",
      " 30  job_descr_len       1124 non-null   int64  \n",
      " 31  python              1124 non-null   float64\n",
      " 32  stack               1124 non-null   float64\n",
      " 33  java                1124 non-null   float64\n",
      " 34  c                   1124 non-null   float64\n",
      " 35  net                 1124 non-null   float64\n",
      " 36  mvc                 1124 non-null   float64\n",
      " 37  mobile              1124 non-null   float64\n",
      " 38  testing             1124 non-null   float64\n",
      " 39  sql                 1124 non-null   float64\n",
      " 40  css                 1124 non-null   float64\n",
      " 41  server              1124 non-null   float64\n",
      " 42  database            1124 non-null   float64\n",
      " 43  html                1124 non-null   float64\n",
      " 44  ui                  1124 non-null   float64\n",
      " 45  system              1124 non-null   float64\n",
      " 46  php                 1124 non-null   float64\n",
      " 47  angular             1124 non-null   float64\n",
      " 48  systems             1124 non-null   float64\n",
      " 49  app                 1124 non-null   float64\n",
      " 50  javascript          1124 non-null   float64\n",
      " 51  rest                1124 non-null   float64\n",
      " 52  api                 1124 non-null   float64\n",
      " 53  js                  1124 non-null   float64\n",
      " 54  cleaning            1124 non-null   float64\n",
      " 55  algorithms          1124 non-null   float64\n",
      " 56  architecture        1124 non-null   float64\n",
      " 57  information         1124 non-null   float64\n",
      " 58  jquery              1124 non-null   float64\n",
      " 59  bootstrap           1124 non-null   float64\n",
      " 60  react               1124 non-null   float64\n",
      " 61  apis                1124 non-null   float64\n",
      "dtypes: float64(37), int32(1), int64(2), object(9), uint8(13)\n",
      "memory usage: 440.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data_prepared.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
