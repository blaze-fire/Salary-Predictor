{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>requirements</th>\n",
       "      <th>rating</th>\n",
       "      <th>experience</th>\n",
       "      <th>posting_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>Agile Placement</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>5,00,000 - 14,00,000 a year</td>\n",
       "      <td>_Strong knowledge of programming and scripting...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Total work: 6 years</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Client of PlaceElements HR</td>\n",
       "      <td>Thiruvananthapuram, Kerala</td>\n",
       "      <td>5,00,000 - 10,00,000 a year</td>\n",
       "      <td>Experience in working closely with data analys...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Python: Algorithms: Statistics: 1 yearData Sci...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Engineer - Machine Learning Engineer</td>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>-999</td>\n",
       "      <td>Experience with machine learning architectures...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning (Fullstack) at Sadhashiva Nag...</td>\n",
       "      <td>Teqlinx Software Solutions LLC</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>30,00,000 a year</td>\n",
       "      <td>• Extremely strong programming background – da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java/J2EE Developer freshers required</td>\n",
       "      <td>www.yansisofsol.com</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>22,000 - 35,000 a month</td>\n",
       "      <td>Sanitising, disinfecting, or cleaning procedur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job_position  \\\n",
       "0                                 Big Data Developer   \n",
       "1                                     Data Scientist   \n",
       "2      Software Engineer - Machine Learning Engineer   \n",
       "3  Machine Learning (Fullstack) at Sadhashiva Nag...   \n",
       "4              Java/J2EE Developer freshers required   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                  Agile Placement   \n",
       "1                       Client of PlaceElements HR   \n",
       "2  Siemens Technology and Services Private Limited   \n",
       "3                   Teqlinx Software Solutions LLC   \n",
       "4                              www.yansisofsol.com   \n",
       "\n",
       "                     Location                       Salary  \\\n",
       "0           Pune, Maharashtra  5,00,000 - 14,00,000 a year   \n",
       "1  Thiruvananthapuram, Kerala  5,00,000 - 10,00,000 a year   \n",
       "2           Pune, Maharashtra                         -999   \n",
       "3        Bengaluru, Karnataka             30,00,000 a year   \n",
       "4        Hyderabad, Telangana      22,000 - 35,000 a month   \n",
       "\n",
       "                                        requirements  rating  \\\n",
       "0  _Strong knowledge of programming and scripting...     0.0   \n",
       "1  Experience in working closely with data analys...     0.0   \n",
       "2  Experience with machine learning architectures...     4.0   \n",
       "3  • Extremely strong programming background – da...     0.0   \n",
       "4  Sanitising, disinfecting, or cleaning procedur...     0.0   \n",
       "\n",
       "                                          experience  posting_frequency  \n",
       "0                                Total work: 6 years                1.0  \n",
       "1  Python: Algorithms: Statistics: 1 yearData Sci...                1.0  \n",
       "2                                                NaN                1.0  \n",
       "3                                                NaN                1.0  \n",
       "4                                                NaN                1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate max and min Salary per annum\n",
    "\n",
    "yearly_min = {}\n",
    "yearly_max = {}\n",
    "\n",
    "def Salary(df):\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        \n",
    "        if df['Salary'][i] == '-999':\n",
    "            yearly_min[i] = 0\n",
    "            yearly_max[i] = 0\n",
    "            \n",
    "        if 'a year' in df['Salary'][i]:\n",
    "            sal_min = df['Salary'][i].split('-')[0].replace('a year','').replace(',','')\n",
    "            yearly_min[i] = int(sal_min)\n",
    "            \n",
    "            try:\n",
    "                sal_max = df['Salary'][i].split('-')[1].replace('a year','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max)\n",
    "                \n",
    "            # if only single value present will be stored in both max and min, so the average comes accuate\n",
    "            except:\n",
    "                sal_max = df['Salary'][i].split('-')[0].replace('a year','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max)\n",
    "            \n",
    "       \n",
    "        if 'a month' in df['Salary'][i]:\n",
    "            sal_min = df['Salary'][i].split('-')[0].replace('a month','').replace(',','')\n",
    "            yearly_min[i] = int(sal_min) * 12\n",
    "            \n",
    "            try:\n",
    "                sal_max = df['Salary'][i].split('-')[1].replace('a month','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 12    \n",
    "                \n",
    "            # if only single value present will be stored in both max and min, so the average comes accuate\n",
    "            except:\n",
    "                sal_max = df['Salary'][i].split('-')[0].replace('a month','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 12\n",
    "                \n",
    "        \n",
    "        if 'an hour' in df['Salary'][i]:\n",
    "            sal_min = df['Salary'][i].split('-')[0].replace('an hour','').replace(',','')\n",
    "            yearly_min[i] = int(sal_min) * 9 * 22 * 12\n",
    "            \n",
    "            try:\n",
    "                sal_max = df['Salary'][i].split('-')[1].replace('an hour','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 9 * 22 * 12  \n",
    "                \n",
    "            # if only single value present will be stored in both max and min, so the average comes accuate\n",
    "            except:\n",
    "                sal_max = df['Salary'][i].split('-')[0].replace('an hour','').replace(',','')\n",
    "                yearly_max[i] = int(sal_max) * 9 * 22 * 12\n",
    "                \n",
    "Salary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min, max and avg Salary columns\n",
    "df['min_Salary'] = pd.DataFrame(yearly_min.values(), index= yearly_min.keys())\n",
    "df['max_Salary'] = pd.DataFrame(yearly_max.values(), index= yearly_max.keys())\n",
    "df['avg_yearly_sal'] = ( df['min_Salary'] + df['max_Salary'] )/2\n",
    "df['monthly_Salary'] = df['avg_yearly_sal']/12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_yearly_sal'].fillna(0, inplace=True)\n",
    "df['min_Salary'].fillna(0, inplace=True)\n",
    "df['max_Salary'].fillna(0, inplace=True)\n",
    "df['monthly_Salary'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just drop these as we got our target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('max_Salary', axis=1, inplace=True)\n",
    "df.drop('min_Salary', axis=1, inplace=True)\n",
    "df.drop('monthly_Salary', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can divide the annual Salary into 6 differrent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_cat'] = pd.cut(df['avg_yearly_sal'], bins=[-999, 0, 50000, 100000, 500000, 1000000, 2500000, np.inf], labels=[-1, 1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Salary', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience is mentioned in both requirements and experience so we will collect them all and save it in a column of experience "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these requirements mention experienced  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience'] = df['experience'].fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_experience = []\n",
    "for i in df.experience:\n",
    "    temp=[]\n",
    "    for word in i.split():\n",
    "        if word.isdigit():\n",
    "            temp.append(word)\n",
    "    if temp:\n",
    "        temp.sort(reverse=True)\n",
    "        net_experience.append(temp[0])\n",
    "    else:\n",
    "        net_experience.append(-99)\n",
    "df['net_experience'] = net_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net_experience'] = df['net_experience'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    for p in ['â', '€', '¦', '“', '¢', '™']:\n",
    "        x.replace(p, ' ')\n",
    "    return x\n",
    "df['requirements'] = df['requirements'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_experience = []\n",
    "for i in df.requirements:\n",
    "    temp=[]\n",
    "    for word in i.split():\n",
    "        if word.isdigit():\n",
    "            temp.append(word)\n",
    "    if temp:\n",
    "        temp.sort(reverse=True)\n",
    "        net_experience.append(temp[0])\n",
    "    else:\n",
    "        net_experience.append(-99)\n",
    "df['exp2'] = net_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unwanted values from experience column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['²', '0080091', '2020', '2024', '2019', '90', '88', '32', '48', '40', '50', '24']:\n",
    "    df['exp2'] = df['exp2'].apply(lambda x: str(x).replace(p,'-99'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exp2'] = df['exp2'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where experience required is mentioned in <b>requirements</b> column but missing in <b>experience</b> column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net_experience'] = df['net_experience'].where((df['net_experience']>0), df['exp2'])\n",
    "df.drop('exp2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python: 1 year'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[294, 'experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     Bachelor’s Degree or higher in data science, S...\n",
       "111    Exposure to cloud-based machine learning platf...\n",
       "122    3+ years business experience including analyti...\n",
       "362    We are looking for an data entry operator And ...\n",
       "749    Good understanding of server-side CSS preproce...\n",
       "Name: requirements, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[14, 111, 122, 362, 749], 'requirements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Some openings require no experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[294, 14, 111, 122, 362, 749], 'net_experience'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some job positions also mention titles lije junior, intern etc. which require 0 experience, we also want to count that where net experience is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    if df.loc[i, 'net_experience'] < 0:\n",
    "        for word in str(df.Job_position[i]).lower().split():\n",
    "            if word == 'jr' or word == 'junior' or word == 'fresher' or word == 'intern' or word == 'intership' or word == 'interns' or word == 'freshers':\n",
    "                df.loc[i, 'net_experience'] = 0\n",
    "            else:\n",
    "                df[i, 'net_experience'] = -99 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Educational criteria mentioned by these companies can also be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_level(data):\n",
    "    if 'bachelor' in data.replace('year',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'bachelor'\n",
    "    if 'secondary' in data.replace('year',' ').replace('(',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'secondary'\n",
    "    if 'master' in data.replace('year',' ').replace(\"'\",' ').lower().split():\n",
    "        return 'masters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'] = df['experience'].map(education_level)\n",
    "df['education_level'].fillna('na',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the categories of seniority is only jr, senior or na, we can one hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['education_level'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seniority of these job positions cal also be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seniority(title):\n",
    "    title = str(title) \n",
    "    if 'ii' in title.lower().split() or 'director' in title.lower().split() or 'specialist' in title.lower().split() or 'professional' in title.lower().split() or 'sr.' in title.lower().split() or 'senior' in title.lower().split():\n",
    "        return 'senior'\n",
    "    elif 'i' in title.lower().split() or 'associate' in title.lower().split() or 'junior' in title.lower().split() or 'jr' in title.lower().split()  or 'jr.' in title.lower().split() or 'trainee' in title.lower().split() or 'intern' in title.lower().split() or 'jr.' in title.lower().split():\n",
    "        return 'jr'\n",
    "    else:\n",
    "        return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the seniority of the position applying for\n",
    "df['job_title'] = df['Job_position'].apply(seniority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding rank transforamtion, label encoding, frequency encoding were applied but they had very weak correlation with avg_year_Salary <br>\n",
    "as the categories of seniority is only jr, senior or na, we can one hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['job_title'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analyzing the requirements column following are the most popular professions <br>\n",
    "lets store their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jobs(data):\n",
    "    data = data.lower().replace(' ', '')\n",
    "    if 'machinelearning' in data:\n",
    "        return 'machine learning'\n",
    "    \n",
    "    if 'datascientist' in data:\n",
    "        return 'data scientist'\n",
    "    \n",
    "    if 'softwaredeveloper' in data:\n",
    "        return 'software developer'\n",
    "    \n",
    "    if 'softwareengineer' in data:\n",
    "        return 'software engineer'\n",
    "    \n",
    "    if 'deeplearning' in data:\n",
    "        return 'deep learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popular_profession'] = df['requirements'].apply(calc_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popular_profession'] = df['popular_profession'].fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['popular_profession'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the location column and get the state \n",
    "df['State'] = df['Location'].apply(lambda x:  x.split(',')[1] if len(x.split(',')) > 1 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can one hot encode these States values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['State'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Larsen & Toubro Infotech Limited    12\n",
       "Accenture                           10\n",
       "Angel & Genie                        8\n",
       "Shaw Academy                         8\n",
       "Barclays                             7\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some companies have multiple job openings this could be useful\n",
    "df['Company'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_openings = df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_openings'] = df['Company'].map(job_openings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['requirements'] = df['requirements'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_descr_len'] = df['requirements'].apply(lambda x: 0 if not x else len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets look at what we have done so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>requirements</th>\n",
       "      <th>rating</th>\n",
       "      <th>experience</th>\n",
       "      <th>posting_frequency</th>\n",
       "      <th>avg_yearly_sal</th>\n",
       "      <th>income_cat</th>\n",
       "      <th>net_experience</th>\n",
       "      <th>...</th>\n",
       "      <th>Jharkhand</th>\n",
       "      <th>Karnataka</th>\n",
       "      <th>Kerala</th>\n",
       "      <th>Maharashtra</th>\n",
       "      <th>Meghalaya</th>\n",
       "      <th>Punjab</th>\n",
       "      <th>Remote</th>\n",
       "      <th>Tamil Nadu</th>\n",
       "      <th>job_openings</th>\n",
       "      <th>job_descr_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Data Developer</td>\n",
       "      <td>Agile Placement</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>_Strong knowledge of programming and scripting...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Total work: 6 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Client of PlaceElements HR</td>\n",
       "      <td>Thiruvananthapuram, Kerala</td>\n",
       "      <td>Experience in working closely with data analys...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Python: Algorithms: Statistics: 1 yearData Sci...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Engineer - Machine Learning Engineer</td>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>Pune, Maharashtra</td>\n",
       "      <td>Experience with machine learning architectures...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning (Fullstack) at Sadhashiva Nag...</td>\n",
       "      <td>Teqlinx Software Solutions LLC</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>• Extremely strong programming background – da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java/J2EE Developer freshers required</td>\n",
       "      <td>www.yansisofsol.com</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>Sanitising, disinfecting, or cleaning procedur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>na</td>\n",
       "      <td>1.0</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job_position  \\\n",
       "0                                 Big Data Developer   \n",
       "1                                     Data Scientist   \n",
       "2      Software Engineer - Machine Learning Engineer   \n",
       "3  Machine Learning (Fullstack) at Sadhashiva Nag...   \n",
       "4              Java/J2EE Developer freshers required   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                  Agile Placement   \n",
       "1                       Client of PlaceElements HR   \n",
       "2  Siemens Technology and Services Private Limited   \n",
       "3                   Teqlinx Software Solutions LLC   \n",
       "4                              www.yansisofsol.com   \n",
       "\n",
       "                     Location  \\\n",
       "0           Pune, Maharashtra   \n",
       "1  Thiruvananthapuram, Kerala   \n",
       "2           Pune, Maharashtra   \n",
       "3        Bengaluru, Karnataka   \n",
       "4        Hyderabad, Telangana   \n",
       "\n",
       "                                        requirements  rating  \\\n",
       "0  _Strong knowledge of programming and scripting...     0.0   \n",
       "1  Experience in working closely with data analys...     0.0   \n",
       "2  Experience with machine learning architectures...     4.0   \n",
       "3  • Extremely strong programming background – da...     0.0   \n",
       "4  Sanitising, disinfecting, or cleaning procedur...     0.0   \n",
       "\n",
       "                                          experience  posting_frequency  \\\n",
       "0                                Total work: 6 years                1.0   \n",
       "1  Python: Algorithms: Statistics: 1 yearData Sci...                1.0   \n",
       "2                                                 na                1.0   \n",
       "3                                                 na                1.0   \n",
       "4                                                 na                1.0   \n",
       "\n",
       "   avg_yearly_sal income_cat  net_experience  ...  Jharkhand  Karnataka  \\\n",
       "0        950000.0          4               6  ...          0          0   \n",
       "1        750000.0          4               2  ...          0          0   \n",
       "2             0.0         -1             -99  ...          0          0   \n",
       "3       3000000.0          6             -99  ...          0          0   \n",
       "4        342000.0          3               0  ...          0          0   \n",
       "\n",
       "   Kerala  Maharashtra  Meghalaya  Punjab  Remote  Tamil Nadu  job_openings  \\\n",
       "0       0            0          0       0       0           0             1   \n",
       "1       0            0          0       0       0           0             1   \n",
       "2       0            0          0       0       0           0             7   \n",
       "3       0            0          0       0       0           0             1   \n",
       "4       0            0          0       0       0           0             1   \n",
       "\n",
       "   job_descr_len  \n",
       "0            158  \n",
       "1            156  \n",
       "2            149  \n",
       "3            160  \n",
       "4            160  \n",
       "\n",
       "[5 rows x 1220 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Job skills\n",
    "\n",
    "As due to covid-19 many people working in the industry have lost their jobs, and according to news articles the skill demand for job industry \n",
    "is also changing, lets take a look at the skills, in demand in the job industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = df['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = list(filter(None, requirements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split punctuation \n",
    "for p in ['-','(',')','.','/']:\n",
    "    job_descr = []\n",
    "    for i in range(0, len(requirements)):\n",
    "        c = requirements[i].split(p)\n",
    "        for x in c:\n",
    "            x.replace('.',' ')\n",
    "            job_descr.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert to lower case\n",
    "for x in range(0,len(job_descr)):\n",
    "    for p in ['.', '-', ')', '(', '…', ',', ':', \"'\"]:\n",
    "        job_descr[x] = job_descr[x].replace(p,' ')\n",
    "    job_descr[x] = job_descr[x].lower()       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing keywords from custom keyword list\n",
    "f = open(\"./utils/skills.txt\",\"r\",) \n",
    "skills=[]\n",
    "for x in f:\n",
    "    skills.append(x)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in skills:\n",
    "    skills = i.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(skills)):\n",
    "    skills[i] = skills[i].replace(' ','')\n",
    "    skills[i] = skills[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['html', 'css', 'c', 'debugging', 'git', 'graphic', 'database', 'java', 'javascript', 'nodejs', 'apis', 'r', 'ruby', 'php', 'net', 'c#', 'jquery', 'python', 'perl', 'react', 'reactjs', 'ux', 'ui', 'testing', 'analyst', 'springboot', 'jpa', 'microservice', 'postman', 'rest', 'api', 'angular', 'azure', 'aws', 'cloud', 'debugging', 'btech', 'cs', 'idbc', 'porting', 'porting', 'vive', 'go', 'playstation', 'medicine', 'food', 'chromium', 'nodejs', 'js', 'net', 'server', 'architecture', 'mobile', 'b2b', 'healthcare', 'security', 'sql', 'mvc', 'asp', 'version', 'typescript', 'sass', 'pwas', 'ios', 'androis', 'html', 'python.node', 'rdbms', 'mysql', 'script', 'query', 'mongo', 'oops', 'os', 'restful', 'app', 'xamarin', 'financial', 'shell', 'unix', 'script', 'powershell', 'linux', 'game', 'gui', 'unity', 'ai', 'jquery', 'iot', 'freelance', 'bootstrap', 'word', 'excel', 'swift', 'salesforce', 'graphic', 'github', 'flutter', 'c++', 'c#', 'docker', 'stack', 'bug', 'lravel', 'flux', 'redux', 'nlp', 'blockchain', 'vue', 'spark', 'flink', 'beam', 'scala', 'operating', 'system', 'statistics', 'structures', 'algorithms', 'mining', 'cleaning', 'open', 'source', 'information', 'systems', 'visualization']\n"
     ]
    }
   ],
   "source": [
    "print(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing requirements on the basis whether a skill is present in that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:4479: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df['requirements'] = df['requirements'].apply(lambda x: ' '.join([word for word in x.lower().split() if word in (skills)]))\n",
    "df['requirements'].replace(to_replace='', value='na', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = word_tokenize(str(job_descr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the frequency of a particular skill mentioned in job description\n",
    "def calc_skill_freq(data):\n",
    "    skill_dict = {}\n",
    "\n",
    "    for i in range(1,len(data)):\n",
    "        token = data[i]\n",
    "        if token in skills:\n",
    "            try:\n",
    "                skill_dict[token].add(i)\n",
    "            except:\n",
    "                skill_dict[token] = {i}\n",
    "            \n",
    "    for i in skill_dict:\n",
    "        skill_dict[i] = len(skill_dict[i])\n",
    "        \n",
    "    return skill_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descr_dict = calc_skill_freq(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Companies have mentioned the required skills in job position and some in some description <br>\n",
    "Lets take a look at the skills mentioned in Job description column, then we will add them to get skills in demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation present in job position column\n",
    "def remove_punctuation(df):\n",
    "    for p in ['/', ',', '(', ')', '-', '|', '&', '_', '.', '“', '”', ':']:\n",
    "        df['Job_position'] = df['Job_position'].apply(lambda x: str(x).replace(p,' '))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_punctuation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing stopwords from custom stopwords list\n",
    "f = open(\"./utils/stopwords.txt\",\"r\",) \n",
    "stopwords=[]\n",
    "\n",
    "for x in f:\n",
    "    stopwords.append(x)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords:\n",
    "    stopwords = i.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(stopwords)):\n",
    "    stopwords[i] = stopwords[i].replace(\"'\",\"\")\n",
    "    stopwords[i] = stopwords[i].replace(\" \",\"\")\n",
    "    stopwords[i] = stopwords[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'developer', 'software', 'etc', 'engineer']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords from the Job_position column\n",
    "job_role = list(df['Job_position'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stopwords)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job_position'] = df['Job_position'].apply(lambda x: ' '.join([word for word in x.lower().split() if word in (skills)]))\n",
    "df['Job_position'] = df['Job_position'].where(df['Job_position'] != '', 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_role = word_tokenize(str(job_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the frequency of a particular skill mentioned in job role\n",
    "job_role_dict = calc_skill_freq(job_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we first pass all the elements of the first dictionary into the third one and then pass the second dictionary \n",
    "into the third. This will replace the duplicate keys of the first dictionary. <br>\n",
    "More info : (https://www.geeksforgeeks.org/python-merging-two-dictionaries/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_dict = {**job_role_dict, **job_descr_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save this dictionary for now it will be useful for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#skill_file = open('./utils/skill_dictionary', 'wb') \n",
    "#pickle.dump(skills_dict, skill_file) \n",
    "#skill_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create new column for each skill with value equal to the frequency of that skill occurring in that particular cell\n",
    "def calc_freq(df):\n",
    "    for key in list(skills_dict.keys()):\n",
    "        if skills_dict[key] > 15:\n",
    "            skill_calc = []\n",
    "            for i in range(0,len(df)):\n",
    "                count = 0\n",
    "                \n",
    "                # here we are counting frquency from both requirements and Job position column\n",
    "                for word in df['requirements'][i].lower().split() :\n",
    "                    if key in df['Job_position'][i].lower().split():\n",
    "                        count += 1\n",
    "                    if key == word:\n",
    "                        count += 1\n",
    "                        skill_calc.append(count)\n",
    "                    else:\n",
    "                        skill_calc.append(0)\n",
    "                        \n",
    "            df = pd.concat([df, pd.DataFrame(skill_calc, columns=[key])], axis=1)\n",
    "            # all the missing values should be filled with zero as they dont contain that particular skill \n",
    "            df[key] = df[key].fillna(0)\n",
    "    return df\n",
    "df = calc_freq(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As skills from job position and description were added its possible some of them dont appear in description, their frequency wiil be zero so we \n",
    "must drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with constant values\n",
    "df = df.loc[:, (df != df.iloc[0]).any()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1737 entries, 0 to 1736\n",
      "Columns: 109 entries, Job_position to apis\n",
      "dtypes: category(1), float64(42), int32(1), int64(2), object(9), uint8(54)\n",
      "memory usage: 819.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./data/data_prepared.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
